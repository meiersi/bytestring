TODO:

    * back port streams fusion code.
    * show instance for LPS
    * stress testing
    * strictness testing
    * rewrite C code to Haskell
    * eliminate use of -fno-warn-orphans

TODO before full builder release
--------------------------------

  [DONE] rename: encodeWithSize ~~> encodeSizePrefixed
  [DONE] fix naming scheme for varInt encodings
  [DONE] switch to Int64 and Int for representing sizes
  [DONE] remove 'Monoidal' type-class
  [DONE] ensure correspondance of 'Contravariant' with 'contravariant' package
  [DONE] merge BasicEncoding.Extras to BasicEncoding
  - add 'variable length encoding builders'
  [DONE] add fast decimal float/double conversion based on blaze-textual.
    Our findings are that the 'blaze-textual' float version is always slower
    than Haskell's built-in version due to the 'realToFrac' conversion. For
    'Double's, Haskell's built-in conversion is sometimes faster and sometimes
    slower than 'blaze-textual'. In no case, one function significantly
    outperforms the other function. We therefore use Haskell's built-in
    version instead of maintaining a complicated piece of code that is anyways
    a lot slower than the 'double-conversion' package. The 'BoundedEncoding'
    type will serve perfectly to wrap the functionality of the
    'double-conversion' package.
  - consider putting builder transformers into a separate package
    'bytestring-builder-transformers'
    (its just too experimental)
  - investigate performance of 'encodeWithListF E.word8'
  - improve performance of varInt encodings
  - improve performance of encodeChunked and encodeWithSize
  - investigate performance of running a one byte builder.
  - fix documentation in BasicEncoding.Extras
  - check all documentation
  - add 'Put' documentation
  - benchmark/test 'Put' merging
  - test 'varInt' encodings
  - test with GHC 6.12, 7.0, 7.2, 7.4
  - add version constraints to all libraries used for testing
    (check that they are referring to the newest versions.)

Todo items
----------

* check that api again.
    - in particular, unsafeHead/Tail for Char8?
    - scanr,scanr1... in Char8

* would it make sense to move the IO bits into a different module too?
        - System.IO.ByteString
        - Data.ByteString.IO

* can we avoid joinWithByte? 
        - Hard. Can't do it easily with a rule.

* think about Data.ByteString.hGetLines. is it needed in the presence of
    the cheap "lines =<< Data.ByteString.Lazy.getContents" ?

* unchunk, Data.ByteString.Lazy -> [Data.ByteString]
    -  and that'd work for any Lazy.ByteString, not just hGetContents >>= lines

* It might be nice to have a trim MutableByteArray primitive that can release
  the tail of an array back to the GC. This would save copying in cases where
  we choose to realloc to save space. This combined with GC-movable strings
  might improve fragmentation / space usage for the many small strings case.

* if we can be sure there is very little variance then it might be interesting to look 
 into the cases where we're doing slightly worse eg the map/up, filter/up cases
 and why we're doing so much better in the up/up case!?  that one makes no sense
 since we should be doing the exact same thing as the old loopU for the up/up
 case

* then there are the strictness issues eg our current foldl & foldr are
  arguably too strict we could fuse unpack/unpackWith if they wern't so strict

* look at shrinking the chunk size, based on our cache testing.

* think about horizontal fusion (esp. when considering nofib code)

* fuseable reverse.

* 'reverse' is very common in list code, but unnecessary in bytestring
  code, since it takes a symmertric view.
    look to eliminate it with rules. loopUp . reverse --> loopDown

* work out how robust the rules are .

* benchmark against C string library benchmarks

* work out if we can convince ghc to remove NoAccs in map and filter.

* Implement Lazy:
    scanl1
    partition
    unzip

* fix documentation in Fusion.hs

* Prelude Data.ByteString.Lazy> List.groupBy (/=) $ [97,99,103,103]
  [[97,99,103,103]]
  Prelude Data.ByteString.Lazy> groupBy (/=) $ pack [97,99,103,103]
  [LPS ["ac","g"],LPS ["g"]]
